{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55744bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.layers import LSTM,Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Sequential,Model,load_model \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c6e2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.30it/s]\n",
      "C:\\Users\\Madhav Gupta\\AppData\\Local\\Temp\\ipykernel_5112\\2771216531.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_files(i) for i in tqdm(all_files,position=0,leave=True)])\n"
     ]
    }
   ],
   "source": [
    "def read_files(file):\n",
    "  notes=[]\n",
    "  notes_to_parse=None\n",
    "  #parse the midi file\n",
    "  midi=converter.parse(file)\n",
    "  #seperate all instruments from the file\n",
    "  instrmt=instrument.partitionByInstrument(midi)\n",
    "\n",
    "  for part in instrmt.parts:\n",
    "    #fetch data only of Piano instrument\n",
    "    if 'Piano' in str(part):\n",
    "      notes_to_parse=part.recurse()\n",
    "\n",
    "      #iterate over all the parts of sub stream elements\n",
    "      #check if element's type is Note or chord\n",
    "      #if it is chord split them into notes\n",
    "      for element in notes_to_parse:\n",
    "        if type(element)==note.Note:\n",
    "          notes.append(str(element.pitch))\n",
    "        elif type(element)==chord.Chord:\n",
    "          notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "  #return the list of notes\n",
    "  return notes\n",
    "\n",
    "#retrieve paths recursively from inside the directories/files\n",
    "file_path=[\"grieg\"]\n",
    "all_files=glob.glob('All Midi Files/'+file_path[0]+'/*.mid',recursive=True)\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_files(i) for i in tqdm(all_files,position=0,leave=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83767630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Notes: 248\n",
      "\n",
      "Frequency notes\n",
      "30 : 116\n",
      "50 : 89\n",
      "70 : 64\n",
      "90 : 51\n"
     ]
    }
   ],
   "source": [
    "#unique notes\n",
    "notess = sum(notes_array,[]) \n",
    "unique_notes = list(set(notess))\n",
    "print(\"Unique Notes:\",len(unique_notes))\n",
    "\n",
    "#notes with their frequency\n",
    "freq=dict(map(lambda x: (x,notess.count(x)),unique_notes))\n",
    "\n",
    "#get the threshold frequency\n",
    "print(\"\\nFrequency notes\")\n",
    "for i in range(30,100,20):\n",
    "  print(i,\":\",len(list(filter(lambda x:x[1]>=i,freq.items()))))\n",
    "\n",
    "#filter notes greater than threshold i.e. 50\n",
    "freq_notes=dict(filter(lambda x:x[1]>=50,freq.items()))\n",
    "\n",
    "#create new notes using the frequent notes\n",
    "new_notes=[[i for i in j if i in freq_notes] for j in notes_array]\n",
    "\n",
    "#dictionary having key as note index and value as note\n",
    "ind2note=dict(enumerate(freq_notes))\n",
    "\n",
    "#dictionary having key as note and value as note index\n",
    "note2ind=dict(map(reversed,ind2note.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654fef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestep\n",
    "timesteps=50\n",
    "\n",
    "#store values of input and output\n",
    "x=[] ; y=[]\n",
    "\n",
    "for i in new_notes:\n",
    "  for j in range(0,len(i)-timesteps):\n",
    "    #input will be the current index + timestep\n",
    "    #output will be the next index after timestep\n",
    "    inp=i[j:j+timesteps] ; out=i[j+timesteps]\n",
    "\n",
    "    #append the index value of respective notes \n",
    "    x.append(list(map(lambda x:note2ind[x],inp)))\n",
    "    y.append(note2ind[out])\n",
    "\n",
    "x_new=np.array(x) \n",
    "y_new=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a95b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape input and output for the model\n",
    "x_new = np.reshape(x_new,(len(x_new),timesteps,1))\n",
    "y_new = np.reshape(y_new,(-1,1))\n",
    "\n",
    "#split the input and value into training and testing sets\n",
    "#80% for training and 20% for testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7981a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 256)           264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 89)                22873     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 878,169\n",
      "Trainable params: 878,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "model = Sequential()\n",
    "#create two stacked LSTM layer with the latent dimension of 256\n",
    "model.add(LSTM(256,return_sequences=True,input_shape=(x_new.shape[1],x_new.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "#fully connected layer for the output with softmax activation\n",
    "model.add(Dense(len(note2ind),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea64bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/74\n",
      "35/35 [==============================] - 59s 1s/step - loss: 4.3593 - accuracy: 0.0311 - val_loss: 4.3247 - val_accuracy: 0.0265\n",
      "Epoch 2/74\n",
      "35/35 [==============================] - 48s 1s/step - loss: 4.2647 - accuracy: 0.0375 - val_loss: 4.2524 - val_accuracy: 0.0352\n",
      "Epoch 3/74\n",
      "35/35 [==============================] - 50s 1s/step - loss: 4.2201 - accuracy: 0.0442 - val_loss: 4.2353 - val_accuracy: 0.0467\n",
      "Epoch 4/74\n",
      "35/35 [==============================] - 53s 2s/step - loss: 4.1624 - accuracy: 0.0560 - val_loss: 4.1770 - val_accuracy: 0.0554\n",
      "Epoch 5/74\n",
      "35/35 [==============================] - 54s 2s/step - loss: 4.0922 - accuracy: 0.0649 - val_loss: 4.1585 - val_accuracy: 0.0636\n",
      "Epoch 6/74\n",
      "35/35 [==============================] - 57s 2s/step - loss: 4.0236 - accuracy: 0.0741 - val_loss: 4.0198 - val_accuracy: 0.0792\n",
      "Epoch 7/74\n",
      "35/35 [==============================] - 60s 2s/step - loss: 3.9102 - accuracy: 0.0897 - val_loss: 3.9580 - val_accuracy: 0.0860\n",
      "Epoch 8/74\n",
      "35/35 [==============================] - 61s 2s/step - loss: 3.7885 - accuracy: 0.1076 - val_loss: 3.8397 - val_accuracy: 0.1066\n",
      "Epoch 9/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 3.6370 - accuracy: 0.1337 - val_loss: 3.7027 - val_accuracy: 0.1318\n",
      "Epoch 10/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 3.4798 - accuracy: 0.1511 - val_loss: 3.6025 - val_accuracy: 0.1524\n",
      "Epoch 11/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 3.3315 - accuracy: 0.1710 - val_loss: 3.4834 - val_accuracy: 0.1693\n",
      "Epoch 12/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 3.1658 - accuracy: 0.1998 - val_loss: 3.3963 - val_accuracy: 0.1707\n",
      "Epoch 13/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 3.0291 - accuracy: 0.2230 - val_loss: 3.3502 - val_accuracy: 0.1863\n",
      "Epoch 14/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 2.8943 - accuracy: 0.2438 - val_loss: 3.2304 - val_accuracy: 0.2119\n",
      "Epoch 15/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 2.7473 - accuracy: 0.2684 - val_loss: 3.1580 - val_accuracy: 0.2146\n",
      "Epoch 16/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 2.6112 - accuracy: 0.2952 - val_loss: 3.1066 - val_accuracy: 0.2297\n",
      "Epoch 17/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 2.4925 - accuracy: 0.3206 - val_loss: 3.0509 - val_accuracy: 0.2302\n",
      "Epoch 18/74\n",
      "35/35 [==============================] - 64s 2s/step - loss: 2.3726 - accuracy: 0.3406 - val_loss: 2.9897 - val_accuracy: 0.2316\n",
      "Epoch 19/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 2.2629 - accuracy: 0.3609 - val_loss: 2.9387 - val_accuracy: 0.2600\n",
      "Epoch 20/74\n",
      "35/35 [==============================] - 64s 2s/step - loss: 2.1561 - accuracy: 0.3863 - val_loss: 2.9074 - val_accuracy: 0.2732\n",
      "Epoch 21/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 2.0502 - accuracy: 0.4151 - val_loss: 2.8597 - val_accuracy: 0.2796\n",
      "Epoch 22/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 1.9350 - accuracy: 0.4409 - val_loss: 2.8156 - val_accuracy: 0.2856\n",
      "Epoch 23/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 1.8654 - accuracy: 0.4546 - val_loss: 2.7701 - val_accuracy: 0.2947\n",
      "Epoch 24/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 1.7859 - accuracy: 0.4766 - val_loss: 2.7279 - val_accuracy: 0.3162\n",
      "Epoch 25/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.6762 - accuracy: 0.5023 - val_loss: 2.7411 - val_accuracy: 0.3108\n",
      "Epoch 26/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 1.6263 - accuracy: 0.5101 - val_loss: 2.7364 - val_accuracy: 0.3085\n",
      "Epoch 27/74\n",
      "35/35 [==============================] - 63s 2s/step - loss: 1.5407 - accuracy: 0.5425 - val_loss: 2.7061 - val_accuracy: 0.3240\n",
      "Epoch 28/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.4545 - accuracy: 0.5597 - val_loss: 2.6705 - val_accuracy: 0.3455\n",
      "Epoch 29/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.3900 - accuracy: 0.5801 - val_loss: 2.6711 - val_accuracy: 0.3478\n",
      "Epoch 30/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.3334 - accuracy: 0.5905 - val_loss: 2.6563 - val_accuracy: 0.3519\n",
      "Epoch 31/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.2451 - accuracy: 0.6230 - val_loss: 2.6416 - val_accuracy: 0.3670\n",
      "Epoch 32/74\n",
      "35/35 [==============================] - 61s 2s/step - loss: 1.1871 - accuracy: 0.6371 - val_loss: 2.6549 - val_accuracy: 0.3634\n",
      "Epoch 33/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.1434 - accuracy: 0.6434 - val_loss: 2.6314 - val_accuracy: 0.3854\n",
      "Epoch 34/74\n",
      "35/35 [==============================] - 61s 2s/step - loss: 1.1197 - accuracy: 0.6529 - val_loss: 2.6456 - val_accuracy: 0.3936\n",
      "Epoch 35/74\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.0614 - accuracy: 0.6717 - val_loss: 2.6528 - val_accuracy: 0.3776\n",
      "Epoch 36/74\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.9858 - accuracy: 0.6972 - val_loss: 2.6477 - val_accuracy: 0.3977\n",
      "Epoch 37/74\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.9239 - accuracy: 0.7196 - val_loss: 2.6902 - val_accuracy: 0.4014\n",
      "Epoch 38/74\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.8984 - accuracy: 0.7204 - val_loss: 2.6468 - val_accuracy: 0.4142\n",
      "Epoch 39/74\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.8407 - accuracy: 0.7402 - val_loss: 2.6769 - val_accuracy: 0.4188\n",
      "Epoch 40/74\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.8040 - accuracy: 0.7514 - val_loss: 2.6859 - val_accuracy: 0.4247\n",
      "Epoch 41/74\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.7743 - accuracy: 0.7620 - val_loss: 2.6984 - val_accuracy: 0.4325\n",
      "Epoch 42/74\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.7443 - accuracy: 0.7639 - val_loss: 2.6776 - val_accuracy: 0.4389\n",
      "Epoch 43/74\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.7373 - accuracy: 0.7695 - val_loss: 2.7008 - val_accuracy: 0.4526\n",
      "Epoch 44/74\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.6777 - accuracy: 0.7862 - val_loss: 2.7152 - val_accuracy: 0.4526\n",
      "Epoch 45/74\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.6434 - accuracy: 0.8021 - val_loss: 2.7281 - val_accuracy: 0.4632\n",
      "Epoch 46/74\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.6268 - accuracy: 0.8041 - val_loss: 2.7417 - val_accuracy: 0.4503\n",
      "Epoch 47/74\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.6337 - accuracy: 0.7990 - val_loss: 2.7525 - val_accuracy: 0.4572\n",
      "Epoch 48/74\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.5620 - accuracy: 0.8220 - val_loss: 2.7526 - val_accuracy: 0.4696\n",
      "Epoch 49/74\n",
      "35/35 [==============================] - 57s 2s/step - loss: 0.5660 - accuracy: 0.8208 - val_loss: 2.8033 - val_accuracy: 0.4682\n",
      "Epoch 50/74\n",
      "35/35 [==============================] - 57s 2s/step - loss: 0.5683 - accuracy: 0.8187 - val_loss: 2.8017 - val_accuracy: 0.4728\n",
      "Epoch 51/74\n",
      "35/35 [==============================] - 57s 2s/step - loss: 0.5087 - accuracy: 0.8435 - val_loss: 2.8162 - val_accuracy: 0.4810\n",
      "Epoch 52/74\n",
      "35/35 [==============================] - 57s 2s/step - loss: 0.4847 - accuracy: 0.8510 - val_loss: 2.8685 - val_accuracy: 0.4870\n",
      "Epoch 53/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.4601 - accuracy: 0.8593 - val_loss: 2.8460 - val_accuracy: 0.4741\n",
      "Epoch 54/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.4569 - accuracy: 0.8596 - val_loss: 2.8947 - val_accuracy: 0.4751\n",
      "Epoch 55/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.4642 - accuracy: 0.8511 - val_loss: 2.9225 - val_accuracy: 0.4842\n",
      "Epoch 56/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.4295 - accuracy: 0.8687 - val_loss: 2.9192 - val_accuracy: 0.4819\n",
      "Epoch 57/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.4101 - accuracy: 0.8742 - val_loss: 2.9410 - val_accuracy: 0.4842\n",
      "Epoch 58/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.3899 - accuracy: 0.8817 - val_loss: 2.9276 - val_accuracy: 0.4860\n",
      "Epoch 59/74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 57s 2s/step - loss: 0.3700 - accuracy: 0.8831 - val_loss: 2.9554 - val_accuracy: 0.4924\n",
      "Epoch 60/74\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.3623 - accuracy: 0.8896 - val_loss: 2.9719 - val_accuracy: 0.4879\n",
      "Epoch 61/74\n",
      "35/35 [==============================] - 31113s 915s/step - loss: 0.3459 - accuracy: 0.8909 - val_loss: 3.0096 - val_accuracy: 0.4851\n",
      "Epoch 62/74\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.3314 - accuracy: 0.8992 - val_loss: 3.0318 - val_accuracy: 0.4943\n",
      "Epoch 63/74\n",
      "35/35 [==============================] - 46s 1s/step - loss: 0.3240 - accuracy: 0.8987 - val_loss: 3.0502 - val_accuracy: 0.5016\n",
      "Epoch 64/74\n",
      "35/35 [==============================] - 50s 1s/step - loss: 0.3102 - accuracy: 0.9055 - val_loss: 3.0746 - val_accuracy: 0.4938\n",
      "Epoch 65/74\n",
      "35/35 [==============================] - 50s 1s/step - loss: 0.3179 - accuracy: 0.9020 - val_loss: 3.0798 - val_accuracy: 0.4998\n",
      "Epoch 66/74\n",
      "35/35 [==============================] - 54s 2s/step - loss: 0.3155 - accuracy: 0.9026 - val_loss: 3.1070 - val_accuracy: 0.4975\n",
      "Epoch 67/74\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.2905 - accuracy: 0.9121 - val_loss: 3.1140 - val_accuracy: 0.5025\n",
      "Epoch 68/74\n",
      "35/35 [==============================] - 46s 1s/step - loss: 0.2820 - accuracy: 0.9143 - val_loss: 3.1174 - val_accuracy: 0.4979\n",
      "Epoch 69/74\n",
      "35/35 [==============================] - 45s 1s/step - loss: 0.2763 - accuracy: 0.9136 - val_loss: 3.1759 - val_accuracy: 0.5002\n",
      "Epoch 70/74\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.2886 - accuracy: 0.9121 - val_loss: 3.1779 - val_accuracy: 0.5016\n",
      "Epoch 71/74\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.2757 - accuracy: 0.9180 - val_loss: 3.2126 - val_accuracy: 0.4957\n",
      "Epoch 72/74\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.2615 - accuracy: 0.9221 - val_loss: 3.1868 - val_accuracy: 0.4998\n",
      "Epoch 73/74\n",
      "35/35 [==============================] - 46s 1s/step - loss: 0.2588 - accuracy: 0.9195 - val_loss: 3.1903 - val_accuracy: 0.5039\n",
      "Epoch 74/74\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.2534 - accuracy: 0.9259 - val_loss: 3.2576 - val_accuracy: 0.4920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9196d43d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile the model using Adam optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#train the model on training sets and validate on testing sets\n",
    "model.fit(\n",
    "    x_train,y_train,\n",
    "    batch_size=256,epochs=74, \n",
    "    validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e564b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MOD\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MOD\\assets\n"
     ]
    }
   ],
   "source": [
    "#save the model for predictions\n",
    "model.save(\"MOD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5774d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model=load_model(\"MOD\")\n",
    "#generate random index\n",
    "index = np.random.randint(0,len(x_test)-1)\n",
    "#get the data of generated index from x_test\n",
    "music_pattern = x_test[index]\n",
    "\n",
    "out_pred=[] #it will store predicted notes\n",
    "\n",
    "#iterate till 200 note is generated\n",
    "for i in range(200):\n",
    "\n",
    "  #reshape the music pattern \n",
    "  music_pattern = music_pattern.reshape(1,len(music_pattern),1)\n",
    "  \n",
    "  #get the maximum probability value from the predicted output\n",
    "  pred_index = np.argmax(model.predict(music_pattern))\n",
    "  #get the note using predicted index and\n",
    "  #append to the output prediction list\n",
    "  out_pred.append(ind2note[pred_index])\n",
    "  music_pattern = np.append(music_pattern,pred_index)\n",
    "  \n",
    "  #update the music pattern with one timestep ahead\n",
    "  music_pattern = music_pattern[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d31bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI_composed_music.mid'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_notes = []\n",
    "for offset,pattern in enumerate(out_pred):\n",
    "  #if pattern is a chord instance\n",
    "  if ('.' in pattern) or pattern.isdigit():\n",
    "    #split notes from the chord\n",
    "    notes_in_chord = pattern.split('.')\n",
    "    notes = []\n",
    "    for current_note in notes_in_chord:\n",
    "        i_curr_note=int(current_note)\n",
    "        #cast the current note to Note object and\n",
    "        #append the current note \n",
    "        new_note = note.Note(i_curr_note)\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        notes.append(new_note)\n",
    "    \n",
    "    #cast the current note to Chord object\n",
    "    #offset will be 1 step ahead from the previous note\n",
    "    #as it will prevent notes to stack up \n",
    "    new_chord = chord.Chord(notes)\n",
    "    new_chord.offset = offset\n",
    "    output_notes.append(new_chord)\n",
    "  \n",
    "  else:\n",
    "    #cast the pattern to Note object apply the offset and \n",
    "    #append the note\n",
    "    new_note = note.Note(pattern)\n",
    "    new_note.offset = offset\n",
    "    new_note.storedInstrument = instrument.Piano()\n",
    "    output_notes.append(new_note)\n",
    "\n",
    "#save the midi file \n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='AI_composed_music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be1f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
